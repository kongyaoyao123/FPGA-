{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing all libraries and creating your Team object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "\n",
    "#import pynq\n",
    "\n",
    "from multiprocessing import Process, Pipe, Queue, Event, Manager, Array\n",
    "img_num = 10000\n",
    "\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capture device is open: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f343496cb8467d9163874cb86a69ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpg', height='720', width='1280')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame_in_w = 640\n",
    "frame_in_h = 360\n",
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FPS, 25);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h);\n",
    "print(\"capture device is open: \" + str(videoIn.isOpened()))\n",
    "imgbox = widgets.Image(format='jpg', height=frame_in_h*2, width=frame_in_w*2)\n",
    "display(imgbox)\n",
    "\n",
    "#print(videoIn.get(cv2.CAP_PROP_FPS),videoIn.get(cv2.CAP_PROP_FRAME_WIDTH),videoIn.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c1faf7b0074b33a105f45ebf5005f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpg', height='300', width='400')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "imgbox = widgets.Image(format='jpg', height=300, width=400)\n",
    "display(imgbox)\n",
    "root = \"D:/yaoyaokong/first_grade_of_graduate/Ultra96/boat2\"\n",
    "for file in os.listdir(root):\n",
    "    canvas = cv2.imread(os.path.join(root, file))\n",
    "    imgbox.value = cv2.imencode('.jpg', canvas)[1].tobytes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Downloading the overlay, perform any any one-time configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "frame_in_w = 640\n",
    "frame_in_h = 360\n",
    "globalimage = [np.zeros((frame_in_w,frame_in_h,3), np.uint8)for i in range(2)]\n",
    "globalimage[0] == globalimage[0][:,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Running MiaoNet****\n",
      "Bitstream loaded\n",
      "Allocating memory done\n",
      "Parameters loading done\n"
     ]
    }
   ],
   "source": [
    "print('\\n**** Running MiaoNet****')\n",
    "\n",
    "xlnk = pynq.Xlnk()\n",
    "xlnk.xlnk_reset()\n",
    "\n",
    "globalimage = np.zeros((frame_in_w,frame_in_h,3), np.uint8)\n",
    "globalimage_out = np.zeros((frame_in_w,frame_in_h,3), np.uint8)\n",
    "\n",
    "################### Download the overlay\n",
    "overlay = pynq.Overlay('dac_sdc.bit')\n",
    "print(\"Bitstream loaded\")\n",
    "\n",
    "########## Allocate memory for weights and off-chip buffers\n",
    "buffer_size = 8\n",
    "cache_flag = 0\n",
    "weight_and_bias = xlnk.cma_array(shape=(32310*8), dtype=np.int16, cacheable = cache_flag)\n",
    "ddr_feature_map_buffer_ping1 = xlnk.cma_array(shape=(4*320*160*8), dtype=np.int16, cacheable = cache_flag)\n",
    "ddr_feature_map_buffer_pong1 = xlnk.cma_array(shape=(4*320*160*8), dtype=np.int16, cacheable = cache_flag)\n",
    "ddr_feature_map_reorg1 = xlnk.cma_array(shape=(120*20*40*8), dtype=np.int16, cacheable = cache_flag)\n",
    "image_pads = [xlnk.cma_array(shape=(160,320,8), dtype=np.int16, cacheable = cache_flag) for i in range(buffer_size)]\n",
    "outputs = [xlnk.cma_array(shape=(2,20,40,8), dtype=np.int16, cacheable = cache_flag) for i in range(buffer_size)]\n",
    "print(\"Allocating memory done\")\n",
    "\n",
    "########### Load parameters from SD card to DDR\n",
    "params = np.fromfile(\"SJTU_microe.bin\", dtype=np.int16)\n",
    "np.copyto(weight_and_bias, params.reshape(weight_and_bias.shape))\n",
    "print(\"Parameters loading done\")\n",
    "\n",
    "\n",
    "\n",
    "################## Utility functions \n",
    "def img_put(image_queue0):\n",
    "    # preprocess for even number images\n",
    "    for index in range(0, img_num, 1):\n",
    "        image_queue0.put(videoIn.read()[1])\n",
    "        if image_queue0.qsize() > 2:\n",
    "            image_queue0.get()\n",
    "        else:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "def preprocess(image_queue0,image_queue1,image_out):\n",
    "    # preprocess for odd number images\n",
    "    for index in range(0, img_num, 1):\n",
    "        globalimage = image_queue0.get()\n",
    "        resized = cv2.resize(globalimage, (320,160))\n",
    "        converted = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "        np.copyto(image_pads[index%buffer_size][:,:,0:3], converted)\n",
    "        image_queue1.put(image_pads[index%buffer_size].physical_address)\n",
    "        image_out.put(globalimage)\n",
    "\n",
    "def postcal(output_queue, result_rectangle):\n",
    "    \n",
    "    while output_queue.empty():\n",
    "        continue\n",
    "    for i in range(0, img_num):    \n",
    "        last_conv_out_pad_quant = outputs[output_queue.get()]\n",
    "        new_out = last_conv_out_pad_quant * 2**-8\n",
    "        new_out = new_out.transpose([0,3,1,2]).reshape([-1,20,40])[0:10].reshape(2,5,20,40).transpose(0,2,3,1)\n",
    "        ianchor, icol, irow = np.unravel_index(new_out[:,:,:,4].argmax(), new_out[:,:,:,4].shape)\n",
    "        if ianchor:\n",
    "            anchor_w, anchor_h = [4.0113013115312155,5.760873975661669]\n",
    "        else:\n",
    "            anchor_w, anchor_h = [1.4940052559648322, 2.3598481287086823]\n",
    "        obox = new_out[ianchor, icol, irow, 0:4]\n",
    "\n",
    "#         x = (sigmoid(obox[0]) + irow) * 8 * 640/320\n",
    "#         y = (sigmoid(obox[1]) + icol) * 8 * 360/160\n",
    "#         w = np.exp(obox[2]) * anchor_w * 8 * 640/320\n",
    "#         h = np.exp(obox[3]) * anchor_h * 8 * 360/160\n",
    "        x = (sigmoid(obox[0]) + irow) * 8 * frame_in_w/320\n",
    "        y = (sigmoid(obox[1]) + icol) * 8 * frame_in_h/160\n",
    "        w = np.exp(obox[2]) * anchor_w * 8 * frame_in_w/320\n",
    "        h = np.exp(obox[3]) * anchor_h * 8 * frame_in_h/160\n",
    "            \n",
    "        x1 = int((x - w/2))\n",
    "        y1 = int((y - h/2))\n",
    "        x2 = int((x + w/2))\n",
    "        y2 = int((y + h/2))\n",
    "        result_rectangle.put([x1,x2,y1,y2])\n",
    "        \n",
    "        \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "################# one-time configuration ##############\n",
    "MiaoNet = overlay.MiaoDetDAC_0\n",
    "MiaoNet.write(0x10, weight_and_bias.physical_address)\n",
    "MiaoNet.write(0x18, ddr_feature_map_buffer_ping1.physical_address)\n",
    "MiaoNet.write(0x20, ddr_feature_map_buffer_ping1.physical_address)\n",
    "MiaoNet.write(0x28, ddr_feature_map_buffer_pong1.physical_address)\n",
    "MiaoNet.write(0x30, ddr_feature_map_buffer_pong1.physical_address)\n",
    "MiaoNet.write(0x38, ddr_feature_map_reorg1.physical_address)\n",
    "MiaoNet.write(0x40, ddr_feature_map_reorg1.physical_address)\n",
    "\n",
    "################# Declare Variable ##############\n",
    "image_queue_size = int(buffer_size/2)-1\n",
    "image_queue0 = Queue(image_queue_size)\n",
    "image_queue1 = Queue(image_queue_size)\n",
    "image_out = Queue(image_queue_size)\n",
    "output_queue = Queue(buffer_size-1)\n",
    "result_rectangle = Queue(2)\n",
    "rails = pynq.get_rails()\n",
    "p1 = Process(target=img_put, args=[image_queue0])\n",
    "p2 = Process(target=postcal, args=(output_queue, result_rectangle))\n",
    "p3 = Process(target=preprocess, args=(image_queue0, image_queue1,image_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Processing all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of CPU is:4\n",
      "child   p.name:Process-17\tp.id10132\n",
      "child   p.name:Process-18\tp.id11516\n",
      "child   p.name:Process-16\tp.id3704\n",
      "END!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-98201c4d83e5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-98201c4d83e5>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    jupyter nbextension enable --py widgetsnbextension\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f1f501ad48bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#capture frame-by-frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#our operation on the frame come here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "\t#capture frame-by-frame\n",
    "    ret , frame = cap.read()\n",
    "    \n",
    "    #our operation on the frame come here\n",
    "    gray = cv2.cvtColor(frame , cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) &0xFF ==ord('q'):  #按q键退出\n",
    "    \tbreak\n",
    "#when everything done , release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Start to detect****\n"
     ]
    }
   ],
   "source": [
    "################### Start to detect ################\n",
    "\n",
    "print(\"\\n**** Start to detect****\")\n",
    "start = time.time()\n",
    "if True:\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p3.start()\n",
    "    for index in range(0, img_num, 1):\n",
    "        # process for even number images\n",
    "        MiaoNet.write(0x58, outputs[index%buffer_size].physical_address) # tell PL which output buffer to write\n",
    "        input_physical_address = image_queue1.get() # get physical address of input buffer from preprocess thread\n",
    "        MiaoNet.write(0x48, input_physical_address) # tell PL which input buffer to read\n",
    "        MiaoNet.write(0x50, input_physical_address) # tell PL which input buffer to read\n",
    "        MiaoNet.write(0x00, 1)  # tell PL to start working\n",
    "        isready = MiaoNet.read(0x00)\n",
    "        \n",
    "        while( isready == 1 ): # wait for PL to finish\n",
    "            isready = MiaoNet.read(0x00)\n",
    "        output_queue.put(index%buffer_size) # tell process-p2 that another image is dealt with\n",
    "        \n",
    "        a = result_rectangle.get() #[x1,x2,y1,y2]\n",
    "        globalimage = image_out.get()\n",
    "        globalimage_out = cv2.rectangle(globalimage,(a[0],a[2]),(a[1],a[3]),(0,0,255),3)\n",
    "        imgbox.value = cv2.imencode('.jpg', globalimage_out)[1].tobytes()\n",
    "#         # process for odd number images\n",
    "#         MiaoNet.write(0x58, outputs[(index+1)%buffer_size].physical_address)\n",
    "#         input_physical_address = image_queue1.get()\n",
    "#         MiaoNet.write(0x48, input_physical_address) \n",
    "#         MiaoNet.write(0x50, input_physical_address) \n",
    "#         MiaoNet.write(0x00, 1)  # tell PL to start working\n",
    "#         isready = MiaoNet.read(0x00)\n",
    "#         while( isready == 1 ): # wait for PL to finish\n",
    "#             isready = MiaoNet.read(0x00)\n",
    "#         output_queue.put((index+1)%buffer_size) # tell process-p2 that another image is dealt with\n",
    "    \n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "        \n",
    "end = time.time()\n",
    "total_time = end - start\n",
    "print('Processing time: {} seconds.'.format(total_time))\n",
    "\n",
    "print(\"**** Detection finished****\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Writing results to XML and any other cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnk.xlnk_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(videoIn.read()[1])\n",
    "#import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "#import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "#import numpy as np\n",
    "#imgbox.value = cv2.imencode('.jpg', videoIn.read()[1])[1].tobytes()\n",
    "frame_in_w = 640\n",
    "frame_in_h = 360\n",
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FPS, 20);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h);\n",
    "print(\"capture device is open: \" + str(videoIn.isOpened()))\n",
    "imgbox = widgets.Image(format='jpg', height=frame_in_h*2, width=frame_in_w*2)\n",
    "display(imgbox)\n",
    "print(videoIn.get(cv2.CAP_PROP_FPS),videoIn.get(cv2.CAP_PROP_FRAME_WIDTH),videoIn.get(cv2.CAP_PROP_FRAME_HEIGHT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################## Utility functions \n",
    "def img_put(image_queue0):\n",
    "    # preprocess for even number images\n",
    "    for index in range(0, img_num, 1):\n",
    "        image_queue0.put(videoIn.read()[1])\n",
    "        if image_queue0.qsize() > 2:\n",
    "            image_queue0.get()\n",
    "        else:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "def preprocess(image_queue0,image_queue1,image_out):\n",
    "    # preprocess for odd number images\n",
    "    for index in range(0, img_num, 1):\n",
    "        globalimage = image_queue0.get()\n",
    "        resized = cv2.resize(globalimage, (320,160))\n",
    "        converted = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "        np.copyto(image_pads[index%buffer_size][:,:,0:3], converted)\n",
    "        image_queue1.put(image_pads[index%buffer_size].physical_address)\n",
    "        image_out.put(globalimage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
